{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Store Images to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_PARASITIZED = \"datasets\\\\Archived\\\\Parasitized\\\\\"\n",
    "FILE_PATH_UNINFECTED = \"datasets\\\\Archived\\\\Uninfected\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized = glob.glob(FILE_PATH_PARASITIZED + \"*.png\")\n",
    "uninfected = glob.glob(FILE_PATH_UNINFECTED + \"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for image in parasitized:\n",
    "    img = cv2.imread(image)\n",
    "    res = cv2.resize(img, dsize=(32,32))\n",
    "    x_list.append(res)\n",
    "    y_list.append(1)\n",
    "    \n",
    "for image in uninfected:\n",
    "    img = cv2.imread(image)\n",
    "    res = cv2.resize(img, dsize=(32,32))\n",
    "    x_list.append(res)\n",
    "    y_list.append(0)\n",
    "    \n",
    "x = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "x = x/255.\n",
    "y = y.reshape((y.shape[0],1))\n",
    "\n",
    "print(\"x.shape: %s\" % str(x.shape))\n",
    "print(\"y.shape: %s\" % str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train = h5py.File(\"train_malaria.h5\", \"w\")\n",
    "hf_train.create_dataset(\"train_set_x\", data=X_train)\n",
    "hf_train.create_dataset(\"train_set_y\", data=y_train)\n",
    "hf_train.close()\n",
    "\n",
    "hf_test = h5py.File(\"test_malaria.h5\", \"w\")\n",
    "hf_test.create_dataset(\"test_set_x\", data=X_test)\n",
    "hf_test.create_dataset(\"test_set_y\", data=y_test)\n",
    "hf_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_malaria.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_malaria.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18463, 32, 32, 3)\n",
      "(18463, 1)\n",
      "(4547, 32, 32, 3)\n",
      "(4547, 1)\n",
      "(4548, 32, 32, 3)\n",
      "(4548, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_dataset()\n",
    "\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X_test, Y_test, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_dev.shape)\n",
    "print(Y_dev.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jann\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 8)         608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 119       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 2,015\n",
      "Trainable params: 2,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5,5), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(8,8), strides=8, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])  \n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "model1.compile(optimizer=optimizer1, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jann\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "18463/18463 [==============================] - 6s 324us/sample - loss: 0.6145 - acc: 0.6587\n",
      "Epoch 2/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.4450 - acc: 0.8013\n",
      "Epoch 3/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.3436 - acc: 0.8586\n",
      "Epoch 4/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.2241 - acc: 0.9160\n",
      "Epoch 5/100\n",
      "18463/18463 [==============================] - 4s 216us/sample - loss: 0.1677 - acc: 0.9417\n",
      "Epoch 6/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1521 - acc: 0.9491\n",
      "Epoch 7/100\n",
      "18463/18463 [==============================] - 4s 211us/sample - loss: 0.1446 - acc: 0.9526\n",
      "Epoch 8/100\n",
      "18463/18463 [==============================] - 4s 212us/sample - loss: 0.1403 - acc: 0.9544\n",
      "Epoch 9/100\n",
      "18463/18463 [==============================] - 4s 195us/sample - loss: 0.1376 - acc: 0.9544\n",
      "Epoch 10/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.1338 - acc: 0.9563\n",
      "Epoch 11/100\n",
      "18463/18463 [==============================] - 4s 216us/sample - loss: 0.1329 - acc: 0.9557\n",
      "Epoch 12/100\n",
      "18463/18463 [==============================] - 4s 220us/sample - loss: 0.1312 - acc: 0.9579\n",
      "Epoch 13/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.1275 - acc: 0.9568\n",
      "Epoch 14/100\n",
      "18463/18463 [==============================] - 4s 207us/sample - loss: 0.1264 - acc: 0.9589\n",
      "Epoch 15/100\n",
      "18463/18463 [==============================] - 3s 186us/sample - loss: 0.1249 - acc: 0.9589\n",
      "Epoch 16/100\n",
      "18463/18463 [==============================] - 4s 210us/sample - loss: 0.1221 - acc: 0.9591\n",
      "Epoch 17/100\n",
      "18463/18463 [==============================] - 4s 205us/sample - loss: 0.1189 - acc: 0.9609\n",
      "Epoch 18/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.1206 - acc: 0.9595\n",
      "Epoch 19/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1177 - acc: 0.9604\n",
      "Epoch 20/100\n",
      "18463/18463 [==============================] - 4s 220us/sample - loss: 0.1142 - acc: 0.9612\n",
      "Epoch 21/100\n",
      "18463/18463 [==============================] - 4s 203us/sample - loss: 0.1138 - acc: 0.9620\n",
      "Epoch 22/100\n",
      "18463/18463 [==============================] - 4s 212us/sample - loss: 0.1135 - acc: 0.9627\n",
      "Epoch 23/100\n",
      "18463/18463 [==============================] - 4s 210us/sample - loss: 0.1130 - acc: 0.9627\n",
      "Epoch 24/100\n",
      "18463/18463 [==============================] - 4s 211us/sample - loss: 0.1103 - acc: 0.9630\n",
      "Epoch 25/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.1075 - acc: 0.9636\n",
      "Epoch 26/100\n",
      "18463/18463 [==============================] - 4s 219us/sample - loss: 0.1066 - acc: 0.9635\n",
      "Epoch 27/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.1058 - acc: 0.9650\n",
      "Epoch 28/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.1055 - acc: 0.9650\n",
      "Epoch 29/100\n",
      "18463/18463 [==============================] - 4s 196us/sample - loss: 0.1034 - acc: 0.9653\n",
      "Epoch 30/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.1020 - acc: 0.9658\n",
      "Epoch 31/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1007 - acc: 0.9665\n",
      "Epoch 32/100\n",
      "18463/18463 [==============================] - 4s 208us/sample - loss: 0.0999 - acc: 0.9653\n",
      "Epoch 33/100\n",
      "18463/18463 [==============================] - 4s 205us/sample - loss: 0.0991 - acc: 0.9659\n",
      "Epoch 34/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.0972 - acc: 0.9670\n",
      "Epoch 35/100\n",
      "18463/18463 [==============================] - 4s 194us/sample - loss: 0.0956 - acc: 0.9672\n",
      "Epoch 36/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.0964 - acc: 0.9661\n",
      "Epoch 37/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.0962 - acc: 0.9682\n",
      "Epoch 38/100\n",
      "18463/18463 [==============================] - 4s 201us/sample - loss: 0.0948 - acc: 0.9671\n",
      "Epoch 39/100\n",
      "18463/18463 [==============================] - 4s 193us/sample - loss: 0.0918 - acc: 0.9686\n",
      "Epoch 40/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0929 - acc: 0.9686\n",
      "Epoch 41/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.0905 - acc: 0.9692\n",
      "Epoch 42/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.0888 - acc: 0.9698\n",
      "Epoch 43/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.0910 - acc: 0.9686\n",
      "Epoch 44/100\n",
      "18463/18463 [==============================] - 4s 211us/sample - loss: 0.0905 - acc: 0.9699\n",
      "Epoch 45/100\n",
      "18463/18463 [==============================] - 4s 203us/sample - loss: 0.0884 - acc: 0.9697\n",
      "Epoch 46/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.0857 - acc: 0.9707\n",
      "Epoch 47/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.0860 - acc: 0.9710\n",
      "Epoch 48/100\n",
      "18463/18463 [==============================] - ETA: 0s - loss: 0.0871 - acc: 0.970 - 4s 195us/sample - loss: 0.0870 - acc: 0.9703\n",
      "Epoch 49/100\n",
      "18463/18463 [==============================] - 4s 216us/sample - loss: 0.0865 - acc: 0.9706\n",
      "Epoch 50/100\n",
      "18463/18463 [==============================] - 4s 203us/sample - loss: 0.0849 - acc: 0.9722\n",
      "Epoch 51/100\n",
      "18463/18463 [==============================] - 4s 196us/sample - loss: 0.0870 - acc: 0.9706\n",
      "Epoch 52/100\n",
      "18463/18463 [==============================] - 3s 142us/sample - loss: 0.0857 - acc: 0.9704\n",
      "Epoch 53/100\n",
      "18463/18463 [==============================] - 4s 193us/sample - loss: 0.0849 - acc: 0.9712\n",
      "Epoch 54/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0825 - acc: 0.9724\n",
      "Epoch 55/100\n",
      "18463/18463 [==============================] - 3s 155us/sample - loss: 0.0826 - acc: 0.9713\n",
      "Epoch 56/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0829 - acc: 0.9717\n",
      "Epoch 57/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0828 - acc: 0.9713\n",
      "Epoch 58/100\n",
      "18463/18463 [==============================] - 3s 152us/sample - loss: 0.0817 - acc: 0.9712\n",
      "Epoch 59/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0814 - acc: 0.9724\n",
      "Epoch 60/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0801 - acc: 0.9731\n",
      "Epoch 61/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0831 - acc: 0.9704\n",
      "Epoch 62/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0786 - acc: 0.9736\n",
      "Epoch 63/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0797 - acc: 0.9726\n",
      "Epoch 64/100\n",
      "18463/18463 [==============================] - 4s 208us/sample - loss: 0.0811 - acc: 0.9728\n",
      "Epoch 65/100\n",
      "18463/18463 [==============================] - 4s 210us/sample - loss: 0.0781 - acc: 0.9728\n",
      "Epoch 66/100\n",
      "18463/18463 [==============================] - 4s 202us/sample - loss: 0.0825 - acc: 0.9719\n",
      "Epoch 67/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.0786 - acc: 0.9721\n",
      "Epoch 68/100\n",
      "18463/18463 [==============================] - 4s 193us/sample - loss: 0.0775 - acc: 0.9736\n",
      "Epoch 69/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0767 - acc: 0.9739\n",
      "Epoch 70/100\n",
      "18463/18463 [==============================] - 2s 131us/sample - loss: 0.0766 - acc: 0.9738\n",
      "Epoch 71/100\n",
      "18463/18463 [==============================] - 3s 140us/sample - loss: 0.0782 - acc: 0.9731\n",
      "Epoch 72/100\n",
      "18463/18463 [==============================] - 2s 133us/sample - loss: 0.0760 - acc: 0.9730\n",
      "Epoch 73/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.0777 - acc: 0.9736\n",
      "Epoch 74/100\n",
      "18463/18463 [==============================] - 4s 202us/sample - loss: 0.0752 - acc: 0.9742\n",
      "Epoch 75/100\n",
      "18463/18463 [==============================] - 3s 152us/sample - loss: 0.0752 - acc: 0.9740\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18463/18463 [==============================] - 3s 144us/sample - loss: 0.0763 - acc: 0.9746\n",
      "Epoch 77/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0744 - acc: 0.9749\n",
      "Epoch 78/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0754 - acc: 0.9737\n",
      "Epoch 79/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.0743 - acc: 0.9752\n",
      "Epoch 80/100\n",
      "18463/18463 [==============================] - 4s 190us/sample - loss: 0.0748 - acc: 0.9743\n",
      "Epoch 81/100\n",
      "18463/18463 [==============================] - 4s 197us/sample - loss: 0.0739 - acc: 0.9738\n",
      "Epoch 82/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0722 - acc: 0.9759\n",
      "Epoch 83/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0735 - acc: 0.9746\n",
      "Epoch 84/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0711 - acc: 0.9765\n",
      "Epoch 85/100\n",
      "18463/18463 [==============================] - 3s 156us/sample - loss: 0.0728 - acc: 0.9746\n",
      "Epoch 86/100\n",
      "18463/18463 [==============================] - 2s 133us/sample - loss: 0.0723 - acc: 0.9754\n",
      "Epoch 87/100\n",
      "18463/18463 [==============================] - 3s 137us/sample - loss: 0.0731 - acc: 0.9749\n",
      "Epoch 88/100\n",
      "18463/18463 [==============================] - 4s 204us/sample - loss: 0.0710 - acc: 0.9760\n",
      "Epoch 89/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0716 - acc: 0.9755\n",
      "Epoch 90/100\n",
      "18463/18463 [==============================] - 2s 135us/sample - loss: 0.0695 - acc: 0.9770\n",
      "Epoch 91/100\n",
      "18463/18463 [==============================] - 4s 198us/sample - loss: 0.0715 - acc: 0.9755\n",
      "Epoch 92/100\n",
      "18463/18463 [==============================] - 4s 206us/sample - loss: 0.0697 - acc: 0.9760\n",
      "Epoch 93/100\n",
      "18463/18463 [==============================] - 4s 196us/sample - loss: 0.0704 - acc: 0.9764\n",
      "Epoch 94/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0695 - acc: 0.9766\n",
      "Epoch 95/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.0690 - acc: 0.9766\n",
      "Epoch 96/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.0673 - acc: 0.9768\n",
      "Epoch 97/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.0709 - acc: 0.9761\n",
      "Epoch 98/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.0673 - acc: 0.9781\n",
      "Epoch 99/100\n",
      "18463/18463 [==============================] - 4s 194us/sample - loss: 0.0675 - acc: 0.9776\n",
      "Epoch 100/100\n",
      "18463/18463 [==============================] - 4s 197us/sample - loss: 0.0654 - acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22106d4bcf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 1s 136us/sample - loss: 0.1720 - acc: 0.9521\n",
      "Dev set accuracy: 0.9520563\n"
     ]
    }
   ],
   "source": [
    "dev_loss, dev_acc = model1.evaluate(X_dev, Y_dev)\n",
    "\n",
    "print('Dev set accuracy:', dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 0s 62us/sample - loss: 0.1812 - acc: 0.9518\n",
      "Test set accuracy: 0.95184696\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test set accuracy:', test_acc)\n",
    "accuracy = []\n",
    "accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2211b0ae240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 999\n",
    "predictions = model1.predict(X_test) > 0.5\n",
    "print(predictions[index])\n",
    "plt.title(\"y = %s\" % Y_test[index])\n",
    "plt.imshow(X_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2211605eda0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(Y_test, predictions, classes=[\"Uninfected\",\"Parasitized\"], title='Confusion matrix on Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 8)         1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 16)          3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 231       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 9,391\n",
      "Trainable params: 9,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(7,7), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(8,8), strides=8, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])  \n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2=tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18463/18463 [==============================] - 4s 226us/sample - loss: 0.6223 - acc: 0.6390\n",
      "Epoch 2/100\n",
      "18463/18463 [==============================] - 4s 200us/sample - loss: 0.4754 - acc: 0.7777\n",
      "Epoch 3/100\n",
      "18463/18463 [==============================] - 4s 206us/sample - loss: 0.4423 - acc: 0.7971\n",
      "Epoch 4/100\n",
      "18463/18463 [==============================] - 4s 243us/sample - loss: 0.3939 - acc: 0.8288\n",
      "Epoch 5/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.3397 - acc: 0.8648\n",
      "Epoch 6/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.2715 - acc: 0.9006\n",
      "Epoch 7/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.2359 - acc: 0.9172\n",
      "Epoch 8/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.2018 - acc: 0.9315\n",
      "Epoch 9/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.1767 - acc: 0.9391\n",
      "Epoch 10/100\n",
      "18463/18463 [==============================] - 4s 219us/sample - loss: 0.1557 - acc: 0.9452\n",
      "Epoch 11/100\n",
      "18463/18463 [==============================] - 4s 224us/sample - loss: 0.1494 - acc: 0.9467\n",
      "Epoch 12/100\n",
      "18463/18463 [==============================] - 4s 242us/sample - loss: 0.1419 - acc: 0.9527\n",
      "Epoch 13/100\n",
      "18463/18463 [==============================] - 4s 200us/sample - loss: 0.1390 - acc: 0.9538\n",
      "Epoch 14/100\n",
      "18463/18463 [==============================] - 3s 161us/sample - loss: 0.1360 - acc: 0.9557\n",
      "Epoch 15/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.1405 - acc: 0.9552\n",
      "Epoch 16/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.1320 - acc: 0.9578\n",
      "Epoch 17/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.1289 - acc: 0.9580\n",
      "Epoch 18/100\n",
      "18463/18463 [==============================] - 4s 222us/sample - loss: 0.1293 - acc: 0.9586\n",
      "Epoch 19/100\n",
      "18463/18463 [==============================] - 4s 207us/sample - loss: 0.1270 - acc: 0.9588\n",
      "Epoch 20/100\n",
      "18463/18463 [==============================] - 4s 194us/sample - loss: 0.1291 - acc: 0.9581\n",
      "Epoch 21/100\n",
      "18463/18463 [==============================] - 4s 197us/sample - loss: 0.1252 - acc: 0.9597\n",
      "Epoch 22/100\n",
      "18463/18463 [==============================] - 4s 211us/sample - loss: 0.1265 - acc: 0.9589\n",
      "Epoch 23/100\n",
      "18463/18463 [==============================] - 4s 190us/sample - loss: 0.1212 - acc: 0.9610\n",
      "Epoch 24/100\n",
      "18463/18463 [==============================] - 4s 229us/sample - loss: 0.1189 - acc: 0.9608\n",
      "Epoch 25/100\n",
      "18463/18463 [==============================] - 4s 217us/sample - loss: 0.1170 - acc: 0.9620\n",
      "Epoch 26/100\n",
      "18463/18463 [==============================] - 4s 223us/sample - loss: 0.1213 - acc: 0.9604\n",
      "Epoch 27/100\n",
      "18463/18463 [==============================] - 4s 199us/sample - loss: 0.1186 - acc: 0.9619\n",
      "Epoch 28/100\n",
      "18463/18463 [==============================] - 3s 157us/sample - loss: 0.1154 - acc: 0.9626\n",
      "Epoch 29/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.1111 - acc: 0.9631\n",
      "Epoch 30/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1123 - acc: 0.9638\n",
      "Epoch 31/100\n",
      "18463/18463 [==============================] - 4s 222us/sample - loss: 0.1117 - acc: 0.9630\n",
      "Epoch 32/100\n",
      "18463/18463 [==============================] - 4s 200us/sample - loss: 0.1069 - acc: 0.9641\n",
      "Epoch 33/100\n",
      "18463/18463 [==============================] - 4s 240us/sample - loss: 0.1067 - acc: 0.9650\n",
      "Epoch 34/100\n",
      "18463/18463 [==============================] - 4s 191us/sample - loss: 0.1032 - acc: 0.9658\n",
      "Epoch 35/100\n",
      "18463/18463 [==============================] - 4s 204us/sample - loss: 0.0983 - acc: 0.9659\n",
      "Epoch 36/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.0991 - acc: 0.9679\n",
      "Epoch 37/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0968 - acc: 0.9678\n",
      "Epoch 38/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0959 - acc: 0.9700\n",
      "Epoch 39/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0944 - acc: 0.9692\n",
      "Epoch 40/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0898 - acc: 0.9704\n",
      "Epoch 41/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0900 - acc: 0.9700\n",
      "Epoch 42/100\n",
      "18463/18463 [==============================] - 3s 156us/sample - loss: 0.0893 - acc: 0.9706\n",
      "Epoch 43/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0889 - acc: 0.9704\n",
      "Epoch 44/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.0888 - acc: 0.9703\n",
      "Epoch 45/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.0875 - acc: 0.9704\n",
      "Epoch 46/100\n",
      "18463/18463 [==============================] - 3s 152us/sample - loss: 0.0817 - acc: 0.9730\n",
      "Epoch 47/100\n",
      "18463/18463 [==============================] - 4s 199us/sample - loss: 0.0807 - acc: 0.9736\n",
      "Epoch 48/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0813 - acc: 0.9731\n",
      "Epoch 49/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0811 - acc: 0.9722\n",
      "Epoch 50/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0773 - acc: 0.9731\n",
      "Epoch 51/100\n",
      "18463/18463 [==============================] - 4s 209us/sample - loss: 0.0753 - acc: 0.9745\n",
      "Epoch 52/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0763 - acc: 0.9742\n",
      "Epoch 53/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0747 - acc: 0.9757\n",
      "Epoch 54/100\n",
      "18463/18463 [==============================] - 4s 190us/sample - loss: 0.0758 - acc: 0.9739\n",
      "Epoch 55/100\n",
      "18463/18463 [==============================] - 3s 145us/sample - loss: 0.0741 - acc: 0.9752\n",
      "Epoch 56/100\n",
      "18463/18463 [==============================] - 3s 153us/sample - loss: 0.0665 - acc: 0.9782\n",
      "Epoch 57/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0728 - acc: 0.9751\n",
      "Epoch 58/100\n",
      "18463/18463 [==============================] - 4s 191us/sample - loss: 0.0721 - acc: 0.9773\n",
      "Epoch 59/100\n",
      "18463/18463 [==============================] - 3s 154us/sample - loss: 0.0657 - acc: 0.9783\n",
      "Epoch 60/100\n",
      "18463/18463 [==============================] - 3s 153us/sample - loss: 0.0690 - acc: 0.9763\n",
      "Epoch 61/100\n",
      "18463/18463 [==============================] - 4s 196us/sample - loss: 0.0634 - acc: 0.9790\n",
      "Epoch 62/100\n",
      "18463/18463 [==============================] - 4s 199us/sample - loss: 0.0644 - acc: 0.9773\n",
      "Epoch 63/100\n",
      "18463/18463 [==============================] - 3s 157us/sample - loss: 0.0625 - acc: 0.9791\n",
      "Epoch 64/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0604 - acc: 0.9795\n",
      "Epoch 65/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.0605 - acc: 0.9796\n",
      "Epoch 66/100\n",
      "18463/18463 [==============================] - 3s 155us/sample - loss: 0.0611 - acc: 0.9786\n",
      "Epoch 67/100\n",
      "18463/18463 [==============================] - 3s 148us/sample - loss: 0.0590 - acc: 0.9803\n",
      "Epoch 68/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0576 - acc: 0.9805\n",
      "Epoch 69/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0575 - acc: 0.9803\n",
      "Epoch 70/100\n",
      "18463/18463 [==============================] - 3s 156us/sample - loss: 0.0557 - acc: 0.9812\n",
      "Epoch 71/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.0573 - acc: 0.9806\n",
      "Epoch 72/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0537 - acc: 0.9815\n",
      "Epoch 73/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.0551 - acc: 0.9822\n",
      "Epoch 74/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0552 - acc: 0.9807\n",
      "Epoch 75/100\n",
      "18463/18463 [==============================] - 3s 145us/sample - loss: 0.0499 - acc: 0.9825\n",
      "Epoch 76/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0531 - acc: 0.9816\n",
      "Epoch 77/100\n",
      "18463/18463 [==============================] - 3s 186us/sample - loss: 0.0484 - acc: 0.9839\n",
      "Epoch 78/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0511 - acc: 0.9828\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 80/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0461 - acc: 0.9850\n",
      "Epoch 81/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.0453 - acc: 0.9846\n",
      "Epoch 82/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0512 - acc: 0.9818\n",
      "Epoch 83/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0459 - acc: 0.9841\n",
      "Epoch 84/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0446 - acc: 0.9847\n",
      "Epoch 85/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0478 - acc: 0.9836\n",
      "Epoch 86/100\n",
      "18463/18463 [==============================] - 3s 187us/sample - loss: 0.0455 - acc: 0.9842\n",
      "Epoch 87/100\n",
      "18463/18463 [==============================] - 4s 198us/sample - loss: 0.0464 - acc: 0.9842\n",
      "Epoch 88/100\n",
      "18463/18463 [==============================] - 4s 192us/sample - loss: 0.0443 - acc: 0.9853\n",
      "Epoch 89/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0390 - acc: 0.9877\n",
      "Epoch 90/100\n",
      "18463/18463 [==============================] - 4s 195us/sample - loss: 0.0429 - acc: 0.9848\n",
      "Epoch 91/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0430 - acc: 0.9855\n",
      "Epoch 92/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0425 - acc: 0.9865\n",
      "Epoch 93/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0419 - acc: 0.9853\n",
      "Epoch 94/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0434 - acc: 0.9846\n",
      "Epoch 95/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0414 - acc: 0.9864\n",
      "Epoch 96/100\n",
      "18463/18463 [==============================] - 3s 157us/sample - loss: 0.0402 - acc: 0.9864\n",
      "Epoch 97/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0392 - acc: 0.9868\n",
      "Epoch 98/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0431 - acc: 0.9845\n",
      "Epoch 99/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0413 - acc: 0.9856\n",
      "Epoch 100/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0369 - acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22116984cc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 108us/sample - loss: 0.2255 - acc: 0.9496\n",
      "Dev set accuracy: 0.9496371\n"
     ]
    }
   ],
   "source": [
    "dev_loss, dev_acc = model2.evaluate(X_dev, Y_dev)\n",
    "\n",
    "print('Dev set accuracy:', dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 0s 72us/sample - loss: 0.2944 - acc: 0.9439\n",
      "Test set accuracy: 0.9439314\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test set accuracy:', test_acc)\n",
    "accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 8)         1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 16)          3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 1, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 231       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 9,503\n",
      "Trainable params: 9,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(7,7), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(8,8), strides=8, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])  \n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer3 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "model3.compile(optimizer=optimizer3, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18463/18463 [==============================] - 4s 200us/sample - loss: 0.6610 - acc: 0.5800\n",
      "Epoch 2/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.5132 - acc: 0.7564\n",
      "Epoch 3/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.4503 - acc: 0.7942\n",
      "Epoch 4/100\n",
      "18463/18463 [==============================] - 3s 187us/sample - loss: 0.3595 - acc: 0.8468\n",
      "Epoch 5/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.2522 - acc: 0.9021\n",
      "Epoch 6/100\n",
      "18463/18463 [==============================] - 4s 226us/sample - loss: 0.1773 - acc: 0.9385\n",
      "Epoch 7/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.1645 - acc: 0.9454\n",
      "Epoch 8/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.1533 - acc: 0.9503\n",
      "Epoch 9/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.1504 - acc: 0.9519\n",
      "Epoch 10/100\n",
      "18463/18463 [==============================] - 4s 205us/sample - loss: 0.1412 - acc: 0.9552\n",
      "Epoch 11/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.1389 - acc: 0.9551\n",
      "Epoch 12/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.1356 - acc: 0.9565\n",
      "Epoch 13/100\n",
      "18463/18463 [==============================] - 4s 201us/sample - loss: 0.1329 - acc: 0.9573\n",
      "Epoch 14/100\n",
      "18463/18463 [==============================] - 4s 216us/sample - loss: 0.1329 - acc: 0.9570\n",
      "Epoch 15/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.1278 - acc: 0.9583\n",
      "Epoch 16/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1259 - acc: 0.9592\n",
      "Epoch 17/100\n",
      "18463/18463 [==============================] - 4s 218us/sample - loss: 0.1250 - acc: 0.9588\n",
      "Epoch 18/100\n",
      "18463/18463 [==============================] - 3s 188us/sample - loss: 0.1213 - acc: 0.9588\n",
      "Epoch 19/100\n",
      "18463/18463 [==============================] - 4s 213us/sample - loss: 0.1198 - acc: 0.9605\n",
      "Epoch 20/100\n",
      "18463/18463 [==============================] - 5s 259us/sample - loss: 0.1198 - acc: 0.9612\n",
      "Epoch 21/100\n",
      "18463/18463 [==============================] - 5s 266us/sample - loss: 0.1171 - acc: 0.9608\n",
      "Epoch 22/100\n",
      "18463/18463 [==============================] - 5s 254us/sample - loss: 0.1148 - acc: 0.9622\n",
      "Epoch 23/100\n",
      "18463/18463 [==============================] - 4s 194us/sample - loss: 0.1140 - acc: 0.9623\n",
      "Epoch 24/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.1119 - acc: 0.9627\n",
      "Epoch 25/100\n",
      "18463/18463 [==============================] - 4s 199us/sample - loss: 0.1057 - acc: 0.9651\n",
      "Epoch 26/100\n",
      "18463/18463 [==============================] - 5s 247us/sample - loss: 0.1076 - acc: 0.9635\n",
      "Epoch 27/100\n",
      "18463/18463 [==============================] - 5s 266us/sample - loss: 0.1054 - acc: 0.9653\n",
      "Epoch 28/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.1042 - acc: 0.9645\n",
      "Epoch 29/100\n",
      "18463/18463 [==============================] - 4s 223us/sample - loss: 0.1003 - acc: 0.9664\n",
      "Epoch 30/100\n",
      "18463/18463 [==============================] - 4s 204us/sample - loss: 0.0989 - acc: 0.9663\n",
      "Epoch 31/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0986 - acc: 0.9659\n",
      "Epoch 32/100\n",
      "18463/18463 [==============================] - 4s 211us/sample - loss: 0.0980 - acc: 0.9679\n",
      "Epoch 33/100\n",
      "18463/18463 [==============================] - 4s 221us/sample - loss: 0.0975 - acc: 0.9666\n",
      "Epoch 34/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0923 - acc: 0.9693\n",
      "Epoch 35/100\n",
      "18463/18463 [==============================] - 4s 201us/sample - loss: 0.0918 - acc: 0.9698\n",
      "Epoch 36/100\n",
      "18463/18463 [==============================] - 4s 191us/sample - loss: 0.0879 - acc: 0.9711\n",
      "Epoch 37/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0909 - acc: 0.9701\n",
      "Epoch 38/100\n",
      "18463/18463 [==============================] - 3s 189us/sample - loss: 0.0874 - acc: 0.9712\n",
      "Epoch 39/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0874 - acc: 0.9711\n",
      "Epoch 40/100\n",
      "18463/18463 [==============================] - 4s 223us/sample - loss: 0.0868 - acc: 0.9708\n",
      "Epoch 41/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0826 - acc: 0.9732\n",
      "Epoch 42/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0826 - acc: 0.9725\n",
      "Epoch 43/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0812 - acc: 0.9735\n",
      "Epoch 44/100\n",
      "18463/18463 [==============================] - 4s 208us/sample - loss: 0.0813 - acc: 0.9733\n",
      "Epoch 45/100\n",
      "18463/18463 [==============================] - 4s 219us/sample - loss: 0.0793 - acc: 0.9734\n",
      "Epoch 46/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0803 - acc: 0.9739\n",
      "Epoch 47/100\n",
      "18463/18463 [==============================] - 4s 201us/sample - loss: 0.0770 - acc: 0.9741\n",
      "Epoch 48/100\n",
      "18463/18463 [==============================] - 4s 237us/sample - loss: 0.0776 - acc: 0.9746\n",
      "Epoch 49/100\n",
      "18463/18463 [==============================] - 4s 200us/sample - loss: 0.0709 - acc: 0.9775\n",
      "Epoch 50/100\n",
      "18463/18463 [==============================] - 4s 214us/sample - loss: 0.0709 - acc: 0.9775\n",
      "Epoch 51/100\n",
      "18463/18463 [==============================] - 4s 223us/sample - loss: 0.0715 - acc: 0.9763\n",
      "Epoch 52/100\n",
      "18463/18463 [==============================] - 5s 263us/sample - loss: 0.0738 - acc: 0.9759\n",
      "Epoch 53/100\n",
      "18463/18463 [==============================] - 5s 266us/sample - loss: 0.0702 - acc: 0.9769\n",
      "Epoch 54/100\n",
      "18463/18463 [==============================] - 4s 226us/sample - loss: 0.0711 - acc: 0.9768\n",
      "Epoch 55/100\n",
      "18463/18463 [==============================] - 4s 195us/sample - loss: 0.0690 - acc: 0.9780\n",
      "Epoch 56/100\n",
      "18463/18463 [==============================] - 4s 204us/sample - loss: 0.0672 - acc: 0.9776\n",
      "Epoch 57/100\n",
      "18463/18463 [==============================] - 4s 205us/sample - loss: 0.0677 - acc: 0.9780\n",
      "Epoch 58/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.0630 - acc: 0.9787\n",
      "Epoch 59/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0656 - acc: 0.9784\n",
      "Epoch 60/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0675 - acc: 0.9778\n",
      "Epoch 61/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0614 - acc: 0.9808\n",
      "Epoch 62/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0642 - acc: 0.9784\n",
      "Epoch 63/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0629 - acc: 0.9793\n",
      "Epoch 64/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0614 - acc: 0.9803\n",
      "Epoch 65/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0597 - acc: 0.9800\n",
      "Epoch 66/100\n",
      "18463/18463 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.980 - 3s 180us/sample - loss: 0.0608 - acc: 0.9803\n",
      "Epoch 67/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0595 - acc: 0.9797\n",
      "Epoch 68/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0593 - acc: 0.9802\n",
      "Epoch 69/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0598 - acc: 0.9809\n",
      "Epoch 70/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0580 - acc: 0.9810\n",
      "Epoch 71/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0571 - acc: 0.9816\n",
      "Epoch 72/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.0571 - acc: 0.9807\n",
      "Epoch 73/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0563 - acc: 0.9802\n",
      "Epoch 74/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0548 - acc: 0.9823\n",
      "Epoch 75/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0540 - acc: 0.9828\n",
      "Epoch 76/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0550 - acc: 0.9822\n",
      "Epoch 77/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0548 - acc: 0.9815\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0523 - acc: 0.9830\n",
      "Epoch 79/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0556 - acc: 0.9814\n",
      "Epoch 80/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0501 - acc: 0.9835\n",
      "Epoch 81/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0508 - acc: 0.9833\n",
      "Epoch 82/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0500 - acc: 0.9846\n",
      "Epoch 83/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0505 - acc: 0.9835\n",
      "Epoch 84/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0515 - acc: 0.9835\n",
      "Epoch 85/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0507 - acc: 0.9829\n",
      "Epoch 86/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0516 - acc: 0.9833\n",
      "Epoch 87/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0467 - acc: 0.9854\n",
      "Epoch 88/100\n",
      "18463/18463 [==============================] - 3s 188us/sample - loss: 0.0504 - acc: 0.9833\n",
      "Epoch 89/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0460 - acc: 0.9849\n",
      "Epoch 90/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0470 - acc: 0.9842\n",
      "Epoch 91/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0469 - acc: 0.9845\n",
      "Epoch 92/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0478 - acc: 0.9836\n",
      "Epoch 93/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0464 - acc: 0.9847\n",
      "Epoch 94/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.0444 - acc: 0.9860\n",
      "Epoch 95/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0460 - acc: 0.9844\n",
      "Epoch 96/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0421 - acc: 0.9867\n",
      "Epoch 97/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0462 - acc: 0.9848\n",
      "Epoch 98/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0469 - acc: 0.9846\n",
      "Epoch 99/100\n",
      "18463/18463 [==============================] - 4s 192us/sample - loss: 0.0412 - acc: 0.9870\n",
      "Epoch 100/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0420 - acc: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x222a48fddd8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 0s 105us/sample - loss: 0.2510 - acc: 0.9466\n",
      "Dev set accuracy: 0.9465582\n"
     ]
    }
   ],
   "source": [
    "dev_loss, dev_acc = model3.evaluate(X_dev, Y_dev)\n",
    "\n",
    "print('Dev set accuracy:', dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 0s 79us/sample - loss: 0.2732 - acc: 0.9481\n",
      "Test set accuracy: 0.94810903\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model3.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test set accuracy:', test_acc)\n",
    "accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 8)         1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 16)          3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 10,025\n",
      "Trainable params: 10,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(7,7), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(8,8), strides=8, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])  \n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer4 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "model4.compile(optimizer=optimizer4, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18463/18463 [==============================] - 3s 188us/sample - loss: 0.6700 - acc: 0.5534\n",
      "Epoch 2/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.5132 - acc: 0.7524\n",
      "Epoch 3/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.4499 - acc: 0.7876\n",
      "Epoch 4/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.3852 - acc: 0.8227\n",
      "Epoch 5/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.3300 - acc: 0.8528\n",
      "Epoch 6/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.2608 - acc: 0.8908\n",
      "Epoch 7/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.1899 - acc: 0.9293\n",
      "Epoch 8/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.1699 - acc: 0.9385\n",
      "Epoch 9/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.1600 - acc: 0.9443\n",
      "Epoch 10/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.1535 - acc: 0.9476\n",
      "Epoch 11/100\n",
      "18463/18463 [==============================] - 3s 161us/sample - loss: 0.1457 - acc: 0.9503\n",
      "Epoch 12/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.1433 - acc: 0.9511\n",
      "Epoch 13/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.1391 - acc: 0.9532\n",
      "Epoch 14/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.1352 - acc: 0.9533\n",
      "Epoch 15/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.1336 - acc: 0.9536\n",
      "Epoch 16/100\n",
      "18463/18463 [==============================] - 3s 161us/sample - loss: 0.1323 - acc: 0.9544\n",
      "Epoch 17/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.1264 - acc: 0.9559\n",
      "Epoch 18/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.1244 - acc: 0.9561\n",
      "Epoch 19/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.1200 - acc: 0.9573\n",
      "Epoch 20/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.1171 - acc: 0.9583\n",
      "Epoch 21/100\n",
      "18463/18463 [==============================] - 3s 161us/sample - loss: 0.1151 - acc: 0.9591\n",
      "Epoch 22/100\n",
      "18463/18463 [==============================] - 3s 161us/sample - loss: 0.1136 - acc: 0.9596\n",
      "Epoch 23/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.1111 - acc: 0.9598\n",
      "Epoch 24/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.1095 - acc: 0.9622\n",
      "Epoch 25/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.1091 - acc: 0.9613\n",
      "Epoch 26/100\n",
      "18463/18463 [==============================] - 3s 187us/sample - loss: 0.1088 - acc: 0.9602\n",
      "Epoch 27/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.1039 - acc: 0.9630\n",
      "Epoch 28/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.1049 - acc: 0.9625\n",
      "Epoch 29/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.1025 - acc: 0.9639\n",
      "Epoch 30/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0963 - acc: 0.9658\n",
      "Epoch 31/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.1010 - acc: 0.9640\n",
      "Epoch 32/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0982 - acc: 0.9653\n",
      "Epoch 33/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.0945 - acc: 0.9664\n",
      "Epoch 34/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0931 - acc: 0.9661\n",
      "Epoch 35/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0907 - acc: 0.9679\n",
      "Epoch 36/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0913 - acc: 0.9678\n",
      "Epoch 37/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0904 - acc: 0.9678\n",
      "Epoch 38/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0895 - acc: 0.9686\n",
      "Epoch 39/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0897 - acc: 0.9689\n",
      "Epoch 40/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0856 - acc: 0.9710\n",
      "Epoch 41/100\n",
      "18463/18463 [==============================] - 4s 195us/sample - loss: 0.0859 - acc: 0.9700\n",
      "Epoch 42/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0845 - acc: 0.9690\n",
      "Epoch 43/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0830 - acc: 0.9712\n",
      "Epoch 44/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0825 - acc: 0.9709\n",
      "Epoch 45/100\n",
      "18463/18463 [==============================] - 3s 184us/sample - loss: 0.0823 - acc: 0.9717\n",
      "Epoch 46/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0774 - acc: 0.9726\n",
      "Epoch 47/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0759 - acc: 0.9732\n",
      "Epoch 48/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0767 - acc: 0.9736\n",
      "Epoch 49/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0770 - acc: 0.9724\n",
      "Epoch 50/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0762 - acc: 0.9732\n",
      "Epoch 51/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0714 - acc: 0.9744\n",
      "Epoch 52/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0726 - acc: 0.9753\n",
      "Epoch 53/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0711 - acc: 0.9748\n",
      "Epoch 54/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0692 - acc: 0.9754\n",
      "Epoch 55/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0686 - acc: 0.9760\n",
      "Epoch 56/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0647 - acc: 0.9780\n",
      "Epoch 57/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0673 - acc: 0.9770\n",
      "Epoch 58/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0658 - acc: 0.9776\n",
      "Epoch 59/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0666 - acc: 0.9769\n",
      "Epoch 60/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0643 - acc: 0.9785\n",
      "Epoch 61/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0613 - acc: 0.9791\n",
      "Epoch 62/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0629 - acc: 0.9794\n",
      "Epoch 63/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0655 - acc: 0.9774\n",
      "Epoch 64/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0624 - acc: 0.9790\n",
      "Epoch 65/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0619 - acc: 0.9791\n",
      "Epoch 66/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0609 - acc: 0.9797\n",
      "Epoch 67/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0593 - acc: 0.9800\n",
      "Epoch 68/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0561 - acc: 0.9823\n",
      "Epoch 69/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0606 - acc: 0.9798\n",
      "Epoch 70/100\n",
      "18463/18463 [==============================] - 3s 158us/sample - loss: 0.0591 - acc: 0.9803\n",
      "Epoch 71/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0562 - acc: 0.9817\n",
      "Epoch 72/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0557 - acc: 0.9812\n",
      "Epoch 73/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0563 - acc: 0.9813\n",
      "Epoch 74/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0555 - acc: 0.9818\n",
      "Epoch 75/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0562 - acc: 0.9809\n",
      "Epoch 76/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0542 - acc: 0.9820\n",
      "Epoch 77/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0538 - acc: 0.9815\n",
      "Epoch 78/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0510 - acc: 0.9838\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18463/18463 [==============================] - 3s 155us/sample - loss: 0.0545 - acc: 0.9811\n",
      "Epoch 80/100\n",
      "18463/18463 [==============================] - 3s 154us/sample - loss: 0.0475 - acc: 0.9844\n",
      "Epoch 81/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0510 - acc: 0.9826\n",
      "Epoch 82/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0508 - acc: 0.9828\n",
      "Epoch 83/100\n",
      "18463/18463 [==============================] - 4s 190us/sample - loss: 0.0478 - acc: 0.9833\n",
      "Epoch 84/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0482 - acc: 0.9845\n",
      "Epoch 85/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0499 - acc: 0.9833\n",
      "Epoch 86/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0527 - acc: 0.9824\n",
      "Epoch 87/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0491 - acc: 0.9836\n",
      "Epoch 88/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0460 - acc: 0.9838\n",
      "Epoch 89/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.0483 - acc: 0.9832\n",
      "Epoch 90/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0425 - acc: 0.9860\n",
      "Epoch 91/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0488 - acc: 0.9836\n",
      "Epoch 92/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0452 - acc: 0.9849\n",
      "Epoch 93/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0451 - acc: 0.9851\n",
      "Epoch 94/100\n",
      "18463/18463 [==============================] - 4s 219us/sample - loss: 0.0462 - acc: 0.9841\n",
      "Epoch 95/100\n",
      "18463/18463 [==============================] - 3s 160us/sample - loss: 0.0439 - acc: 0.9852\n",
      "Epoch 96/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0429 - acc: 0.9861\n",
      "Epoch 97/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0460 - acc: 0.9852\n",
      "Epoch 98/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0445 - acc: 0.9848\n",
      "Epoch 99/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0399 - acc: 0.9865\n",
      "Epoch 100/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0401 - acc: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x222e967b978>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 1s 132us/sample - loss: 0.2386 - acc: 0.9488\n",
      "Dev set accuracy: 0.9487574\n"
     ]
    }
   ],
   "source": [
    "dev_loss, dev_acc = model4.evaluate(X_dev, Y_dev)\n",
    "\n",
    "print('Dev set accuracy:', dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 0s 90us/sample - loss: 0.2576 - acc: 0.9439\n",
      "Test set accuracy: 0.9439314\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model4.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test set accuracy:', test_acc)\n",
    "accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 8)         608       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 8)         1608      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,681\n",
      "Trainable params: 3,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5,5), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5,5), strides=1, padding=\"same\", activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(8,8), strides=8, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=1, padding=\"same\", activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=4, padding=\"same\"),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])  \n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18463/18463 [==============================] - 4s 201us/sample - loss: 0.5598 - acc: 0.7069\n",
      "Epoch 2/100\n",
      "18463/18463 [==============================] - 4s 191us/sample - loss: 0.2164 - acc: 0.9179\n",
      "Epoch 3/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.1474 - acc: 0.9501\n",
      "Epoch 4/100\n",
      "18463/18463 [==============================] - 4s 215us/sample - loss: 0.1352 - acc: 0.9547\n",
      "Epoch 5/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.1298 - acc: 0.9568\n",
      "Epoch 6/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.1248 - acc: 0.9579\n",
      "Epoch 7/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.1213 - acc: 0.9599\n",
      "Epoch 8/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.1177 - acc: 0.9594\n",
      "Epoch 9/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.1147 - acc: 0.9602\n",
      "Epoch 10/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.1114 - acc: 0.9619\n",
      "Epoch 11/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.1087 - acc: 0.9621\n",
      "Epoch 12/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.1074 - acc: 0.9639\n",
      "Epoch 13/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.1022 - acc: 0.9648\n",
      "Epoch 14/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0994 - acc: 0.9660\n",
      "Epoch 15/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.1004 - acc: 0.9663\n",
      "Epoch 16/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.1010 - acc: 0.9653\n",
      "Epoch 17/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0958 - acc: 0.9678\n",
      "Epoch 18/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0943 - acc: 0.9670\n",
      "Epoch 19/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0924 - acc: 0.9671\n",
      "Epoch 20/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0894 - acc: 0.9693\n",
      "Epoch 21/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0881 - acc: 0.9691\n",
      "Epoch 22/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0880 - acc: 0.9696\n",
      "Epoch 23/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0852 - acc: 0.9708\n",
      "Epoch 24/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0843 - acc: 0.9706\n",
      "Epoch 25/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0820 - acc: 0.9729\n",
      "Epoch 26/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0801 - acc: 0.9720\n",
      "Epoch 27/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0807 - acc: 0.9728\n",
      "Epoch 28/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0792 - acc: 0.9729\n",
      "Epoch 29/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0764 - acc: 0.9737\n",
      "Epoch 30/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0749 - acc: 0.9739\n",
      "Epoch 31/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0741 - acc: 0.9745\n",
      "Epoch 32/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0732 - acc: 0.9756\n",
      "Epoch 33/100\n",
      "18463/18463 [==============================] - 3s 162us/sample - loss: 0.0703 - acc: 0.9770\n",
      "Epoch 34/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0684 - acc: 0.9772\n",
      "Epoch 35/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0697 - acc: 0.9762\n",
      "Epoch 36/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0666 - acc: 0.9776\n",
      "Epoch 37/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0679 - acc: 0.9772\n",
      "Epoch 38/100\n",
      "18463/18463 [==============================] - 3s 176us/sample - loss: 0.0671 - acc: 0.9763\n",
      "Epoch 39/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0638 - acc: 0.9781\n",
      "Epoch 40/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0634 - acc: 0.9784\n",
      "Epoch 41/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0628 - acc: 0.9783\n",
      "Epoch 42/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0596 - acc: 0.9797\n",
      "Epoch 43/100\n",
      "18463/18463 [==============================] - 3s 187us/sample - loss: 0.0607 - acc: 0.9778\n",
      "Epoch 44/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0585 - acc: 0.9799\n",
      "Epoch 45/100\n",
      "18463/18463 [==============================] - 3s 180us/sample - loss: 0.0597 - acc: 0.9797\n",
      "Epoch 46/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0571 - acc: 0.9813\n",
      "Epoch 47/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0598 - acc: 0.9788\n",
      "Epoch 48/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0541 - acc: 0.9810\n",
      "Epoch 49/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0537 - acc: 0.9817\n",
      "Epoch 50/100\n",
      "18463/18463 [==============================] - 3s 182us/sample - loss: 0.0542 - acc: 0.9816\n",
      "Epoch 51/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0546 - acc: 0.9803\n",
      "Epoch 52/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0491 - acc: 0.9826\n",
      "Epoch 53/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0516 - acc: 0.9809\n",
      "Epoch 54/100\n",
      "18463/18463 [==============================] - 3s 187us/sample - loss: 0.0493 - acc: 0.9834\n",
      "Epoch 55/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0497 - acc: 0.9829\n",
      "Epoch 56/100\n",
      "18463/18463 [==============================] - 3s 185us/sample - loss: 0.0492 - acc: 0.9829\n",
      "Epoch 57/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0450 - acc: 0.9849\n",
      "Epoch 58/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0453 - acc: 0.9846\n",
      "Epoch 59/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0463 - acc: 0.9835\n",
      "Epoch 60/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0420 - acc: 0.9860\n",
      "Epoch 61/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0442 - acc: 0.9851\n",
      "Epoch 62/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0431 - acc: 0.9858\n",
      "Epoch 63/100\n",
      "18463/18463 [==============================] - 5s 256us/sample - loss: 0.0415 - acc: 0.9850\n",
      "Epoch 64/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0388 - acc: 0.9855\n",
      "Epoch 65/100\n",
      "18463/18463 [==============================] - 3s 172us/sample - loss: 0.0461 - acc: 0.9833\n",
      "Epoch 66/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0382 - acc: 0.9871\n",
      "Epoch 67/100\n",
      "18463/18463 [==============================] - 3s 164us/sample - loss: 0.0384 - acc: 0.9869\n",
      "Epoch 68/100\n",
      "18463/18463 [==============================] - 3s 170us/sample - loss: 0.0393 - acc: 0.9867\n",
      "Epoch 69/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0429 - acc: 0.9840\n",
      "Epoch 70/100\n",
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0394 - acc: 0.9856\n",
      "Epoch 71/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0376 - acc: 0.9871\n",
      "Epoch 72/100\n",
      "18463/18463 [==============================] - 3s 165us/sample - loss: 0.0366 - acc: 0.9860\n",
      "Epoch 73/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0341 - acc: 0.9878\n",
      "Epoch 74/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0359 - acc: 0.9875\n",
      "Epoch 75/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0379 - acc: 0.9857\n",
      "Epoch 76/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0360 - acc: 0.9877\n",
      "Epoch 77/100\n",
      "18463/18463 [==============================] - 3s 163us/sample - loss: 0.0333 - acc: 0.9881\n",
      "Epoch 78/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0331 - acc: 0.9881\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18463/18463 [==============================] - 3s 169us/sample - loss: 0.0335 - acc: 0.9886\n",
      "Epoch 80/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0324 - acc: 0.9882\n",
      "Epoch 81/100\n",
      "18463/18463 [==============================] - 3s 174us/sample - loss: 0.0318 - acc: 0.9887\n",
      "Epoch 82/100\n",
      "18463/18463 [==============================] - 3s 179us/sample - loss: 0.0337 - acc: 0.9879\n",
      "Epoch 83/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0301 - acc: 0.9897\n",
      "Epoch 84/100\n",
      "18463/18463 [==============================] - 3s 183us/sample - loss: 0.0377 - acc: 0.9856\n",
      "Epoch 85/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0313 - acc: 0.9885\n",
      "Epoch 86/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0301 - acc: 0.9897\n",
      "Epoch 87/100\n",
      "18463/18463 [==============================] - 3s 171us/sample - loss: 0.0311 - acc: 0.9888\n",
      "Epoch 88/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0315 - acc: 0.9887\n",
      "Epoch 89/100\n",
      "18463/18463 [==============================] - 3s 178us/sample - loss: 0.0297 - acc: 0.9889\n",
      "Epoch 90/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0324 - acc: 0.9885\n",
      "Epoch 91/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0270 - acc: 0.9907\n",
      "Epoch 92/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0269 - acc: 0.9903\n",
      "Epoch 93/100\n",
      "18463/18463 [==============================] - 3s 181us/sample - loss: 0.0289 - acc: 0.9893\n",
      "Epoch 94/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0314 - acc: 0.9879\n",
      "Epoch 95/100\n",
      "18463/18463 [==============================] - 3s 173us/sample - loss: 0.0287 - acc: 0.9896\n",
      "Epoch 96/100\n",
      "18463/18463 [==============================] - 3s 167us/sample - loss: 0.0281 - acc: 0.9904\n",
      "Epoch 97/100\n",
      "18463/18463 [==============================] - 3s 177us/sample - loss: 0.0268 - acc: 0.9904\n",
      "Epoch 98/100\n",
      "18463/18463 [==============================] - 3s 166us/sample - loss: 0.0273 - acc: 0.9900\n",
      "Epoch 99/100\n",
      "18463/18463 [==============================] - 3s 168us/sample - loss: 0.0269 - acc: 0.9900\n",
      "Epoch 100/100\n",
      "18463/18463 [==============================] - 3s 175us/sample - loss: 0.0273 - acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x222eff44a90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 1s 154us/sample - loss: 0.2533 - acc: 0.9461\n",
      "Dev set accuracy: 0.9461183\n"
     ]
    }
   ],
   "source": [
    "dev_loss, dev_acc = model5.evaluate(X_dev, Y_dev)\n",
    "\n",
    "print('Dev set accuracy:', dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4548/4548 [==============================] - 0s 87us/sample - loss: 0.2661 - acc: 0.9468\n",
      "Test set accuracy: 0.9467898\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model5.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test set accuracy:', test_acc)\n",
    "accuracy.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 accuracy: 0.95184696\n",
      "model 2 accuracy: 0.9439314\n",
      "model 3 accuracy: 0.94810903\n",
      "model 4 accuracy: 0.9439314\n",
      "model 5 accuracy: 0.9467898\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"model \"+str(i+1)+\" accuracy: \" +str(accuracy[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
